{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    c = s.lower().strip()\n",
    "    return re.sub('[^a-z ]', '', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_word_class(tag):\n",
    "    if tag in ['JJ', 'JJR', 'JJS']:\n",
    "        return 1 #'adjective'\n",
    "    if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "        return 2 #'noun'\n",
    "    if tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "        return 3 #'verb'\n",
    "    if tag in ['CC', 'IN']:\n",
    "        return 4 #'link'\n",
    "    return 5 #'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_tagging(sentence):\n",
    "    translation = list()\n",
    "    for word, tag in sentence:\n",
    "        translation.append((word, translate_word_class(tag)))\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_encoding(sentence):\n",
    "    encoded = list()\n",
    "    for word, tag in sentence:\n",
    "        encodedInt = one_hot(word,300000)[0]\n",
    "        encoded.append([encodedInt,tag])\n",
    "    return encoded        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "END = 6\n",
    "def sentence_labeling(sentence):\n",
    "    labels = list()\n",
    "    for word, tag in sentence[1:]:\n",
    "        labels.append(tag)\n",
    "    labels.append(END)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_words(sentences):\n",
    "    tagged_words = list()\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words.append(nltk.pos_tag(words))\n",
    "    return tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sentences = list()\n",
    "with open('./data_set/training_set70.txt') as train:\n",
    "    for line in train:\n",
    "        train_sentences.append(clean_sentence(line))\n",
    "\n",
    "test_sentences = list()\n",
    "with open('./data_set/test_set25.txt') as train:\n",
    "    for line in train:\n",
    "        test_sentences.append(clean_sentence(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct', 'dick agreed', 'sorry wrong', 'where is mary', 'he is happy now']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sentences = tag_words(train_sentences)\n",
    "tagged_sentences_test = tag_words(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('sam', 'JJ'), ('didnt', 'NNS'), ('like', 'IN'), ('elections', 'NNS')],\n",
       " [('dick', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('sam', 'NN'),\n",
       "  ('were', 'VBD'),\n",
       "  ('disappointed', 'JJ')],\n",
       " [('where', 'WRB'), ('is', 'VBZ'), ('my', 'PRP$'), ('apple', 'NN')],\n",
       " [('yes', 'RB'), ('thats', 'NNS'), ('correct', 'VBP')],\n",
       " [('no', 'DT'), ('its', 'PRP$'), ('wrong', 'NN')]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[:5]\n",
    "tagged_sentences_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tagged_sentences = list(map(map_tagging, tagged_sentences))\n",
    "test_tagged_sentences = list(map(map_tagging, tagged_sentences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('correct', 2)],\n",
       " [('dick', 2), ('agreed', 3)],\n",
       " [('sorry', 2), ('wrong', 1)],\n",
       " [('where', 5), ('is', 3), ('mary', 1)],\n",
       " [('he', 5), ('is', 3), ('happy', 1), ('now', 5)]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tagged_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = flatten(map(map_encoding, my_tagged_sentences))\n",
    "test = flatten(map(map_encoding, test_tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_matrix(numbers,size,var_index):\n",
    "    matrix = np.zeros((size,1))\n",
    "    sub_matrix = np.zeros((1))\n",
    "    i = 0\n",
    "    for number in numbers:\n",
    "        sub_matrix[0] = number[var_index]\n",
    "        matrix[i][0] = sub_matrix\n",
    "        i=i+1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15753.]\n",
      " [  51163.]\n",
      " [ 121689.]]\n",
      "[[ 2.]\n",
      " [ 2.]\n",
      " [ 3.]]\n",
      "328\n",
      "328\n",
      "[[ 228419.]\n",
      " [ 233806.]\n",
      " [ 214517.]]\n",
      "[[ 1.]\n",
      " [ 2.]\n",
      " [ 4.]]\n",
      "132\n",
      "132\n"
     ]
    }
   ],
   "source": [
    "x_train = create_matrix(x,len(x),0)\n",
    "y_train = create_matrix(x,len(x),1)\n",
    "x_test = create_matrix(test,len(test),0)\n",
    "y_test = create_matrix(test,len(test),1)\n",
    "print(x_train[:3])\n",
    "print(y_train[:3])\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(x_test[:3])\n",
    "print(y_test[:3])\n",
    "print(len(x_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 328 samples, validate on 132 samples\n",
      "Epoch 1/15\n",
      "328/328 [==============================] - 31s - loss: 0.6219 - acc: 0.0671 - val_loss: 0.5071 - val_acc: 0.0606\n",
      "Epoch 2/15\n",
      "328/328 [==============================] - 29s - loss: 0.3935 - acc: 0.0793 - val_loss: 0.2220 - val_acc: 0.0606\n",
      "Epoch 3/15\n",
      "328/328 [==============================] - 29s - loss: 0.0175 - acc: 0.0793 - val_loss: -0.2676 - val_acc: 0.0606\n",
      "Epoch 4/15\n",
      "328/328 [==============================] - 30s - loss: -0.6218 - acc: 0.0793 - val_loss: -1.1053 - val_acc: 0.0606\n",
      "Epoch 5/15\n",
      "328/328 [==============================] - 29s - loss: -1.8197 - acc: 0.0793 - val_loss: -2.5462 - val_acc: 0.0606\n",
      "Epoch 6/15\n",
      "328/328 [==============================] - 28s - loss: -3.6793 - acc: 0.0793 - val_loss: -4.8093 - val_acc: 0.0606\n",
      "Epoch 7/15\n",
      "328/328 [==============================] - 29s - loss: -6.7291 - acc: 0.0793 - val_loss: -8.3634 - val_acc: 0.0606\n",
      "Epoch 8/15\n",
      "328/328 [==============================] - 29s - loss: -10.8728 - acc: 0.0793 - val_loss: -13.2651 - val_acc: 0.0606\n",
      "Epoch 9/15\n",
      "328/328 [==============================] - 32s - loss: -16.6524 - acc: 0.0793 - val_loss: -19.2344 - val_acc: 0.0606\n",
      "Epoch 10/15\n",
      "328/328 [==============================] - 33s - loss: -20.7877 - acc: 0.0793 - val_loss: -23.9831 - val_acc: 0.0606\n",
      "Epoch 11/15\n",
      "328/328 [==============================] - 30s - loss: -23.8414 - acc: 0.0793 - val_loss: -28.0109 - val_acc: 0.0606\n",
      "Epoch 12/15\n",
      "328/328 [==============================] - 39s - loss: -24.7226 - acc: 0.0793 - val_loss: -30.5727 - val_acc: 0.0606\n",
      "Epoch 13/15\n",
      "328/328 [==============================] - 40s - loss: -29.0478 - acc: 0.0793 - val_loss: -32.2086 - val_acc: 0.0606\n",
      "Epoch 14/15\n",
      "328/328 [==============================] - 40s - loss: -26.8065 - acc: 0.0793 - val_loss: -33.1003 - val_acc: 0.0606\n",
      "Epoch 15/15\n",
      "328/328 [==============================] - 46s - loss: -27.4110 - acc: 0.0793 - val_loss: -33.3122 - val_acc: 0.0606\n",
      "132/132 [==============================] - 3s     \n",
      "Test score: -33.3121987545\n",
      "Test accuracy: 0.0606060606061\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(300000, 128, dropout=0.2))\n",
    "model.add(LSTM(128, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=32, nb_epoch=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            32)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-28b3b54cf997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_labeling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_tagged_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flatten' is not defined"
     ]
    }
   ],
   "source": [
    "\"y = flatten(map(sentence_labeling, my_tagged_sentences))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 6, 1, 6]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"y[:5]\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
