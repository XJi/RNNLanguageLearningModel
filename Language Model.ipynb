{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tag the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    c = s.lower().strip()\n",
    "    return re.sub('[^a-z ]', '', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate_word_class(tag):\n",
    "    if tag in ['JJ', 'JJR', 'JJS']:\n",
    "        return 1 #'adjective'\n",
    "    if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "        return 2 #'noun'\n",
    "    if tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "        return 3 #'verb'\n",
    "    if tag in ['CC', 'IN']:\n",
    "        return 4 #'link'\n",
    "    return 5 #'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_tagging(sentence):\n",
    "    translation = list()\n",
    "    for word, tag in sentence:\n",
    "        translation.append((word, translate_word_class(tag)))\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def map_encoding(sentence):\n",
    "    encoded = list()\n",
    "    for word, tag in sentence:\n",
    "        encodedInt = one_hot(word,30000)[0]\n",
    "        encoded.append([encodedInt,tag])\n",
    "    return encoded        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "END = 6\n",
    "def sentence_labeling(sentence):\n",
    "    labels = list()\n",
    "    for word, tag in sentence[1:]:\n",
    "        labels.append(tag)\n",
    "    labels.append(END)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_words(sentences):\n",
    "    tagged_words = list()\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tagged_words.append(nltk.pos_tag(words))\n",
    "    return tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_sentences = list()\n",
    "with open('./data_set/training_set70.txt') as train:\n",
    "    for line in train:\n",
    "        train_sentences.append(clean_sentence(line))\n",
    "\n",
    "test_sentences = list()\n",
    "with open('./data_set/test_set25.txt') as train:\n",
    "    for line in train:\n",
    "        test_sentences.append(clean_sentence(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['correct', 'dick agreed', 'sorry wrong', 'where is mary', 'he is happy now']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sentences = tag_words(train_sentences)\n",
    "tagged_sentences_test = tag_words(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('sam', 'JJ'), ('didnt', 'NNS'), ('like', 'IN'), ('elections', 'NNS')],\n",
       " [('dick', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('sam', 'NN'),\n",
       "  ('were', 'VBD'),\n",
       "  ('disappointed', 'JJ')],\n",
       " [('where', 'WRB'), ('is', 'VBZ'), ('my', 'PRP$'), ('apple', 'NN')],\n",
       " [('yes', 'RB'), ('thats', 'NNS'), ('correct', 'VBP')],\n",
       " [('no', 'DT'), ('its', 'PRP$'), ('wrong', 'NN')]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[:5]\n",
    "tagged_sentences_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_tagged_sentences = list(map(map_tagging, tagged_sentences))\n",
    "test_tagged_sentences = list(map(map_tagging, tagged_sentences_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('correct', 2)],\n",
       " [('dick', 2), ('agreed', 3)],\n",
       " [('sorry', 2), ('wrong', 1)],\n",
       " [('where', 5), ('is', 3), ('mary', 1)],\n",
       " [('he', 5), ('is', 3), ('happy', 1), ('now', 5)]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tagged_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = flatten(map(map_encoding, my_tagged_sentences))\n",
    "test = flatten(map(map_encoding, test_tagged_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_Xmatrix(numbers,size,var_index):\n",
    "    matrix = np.zeros((size,1))\n",
    "    sub_matrix = np.zeros((1))\n",
    "    i = 0\n",
    "    for number in numbers:\n",
    "        sub_matrix[0] = number[var_index]\n",
    "        matrix[i][0] = sub_matrix\n",
    "        i=i+1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_Ymatrix(numbers,size,var_index):\n",
    "    matrix = np.zeros((size))\n",
    "    i = 0\n",
    "    for number in numbers:\n",
    "        matrix[i] = number[var_index]\n",
    "        i=i+1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (328, 1)\n",
      "X_test shape: (132, 1)\n",
      "y_train shape: (328,)\n",
      "y_test shape: (132,)\n",
      "[ 1.  2.  4.  2.  2.  4.  2.  3.  1.  5.  3.  5.  2.  5.  2.  3.  5.  5.\n",
      "  2.  2.  3.  5.  2.  4.  5.  2.  2.  4.  2.  3.  5.  2.  5.  2.  3.  3.\n",
      "  5.  3.  5.  1.  2.  3.  5.  2.  2.  4.  2.  3.  5.  5.  2.  2.  3.  5.\n",
      "  2.  5.  3.  5.  3.  4.  5.  2.  2.  3.  1.  4.  3.  2.  3.  5.  2.  1.\n",
      "  2.  3.  5.  2.  2.  5.  3.  2.  4.  5.  1.  3.  5.  2.  2.  3.  1.  4.\n",
      "  5.  2.  2.  4.  1.  3.  5.  5.  2.  2.  5.  3.  4.  5.  2.  5.  3.  5.\n",
      "  5.  5.  2.  5.  3.  5.  2.  4.  5.  2.  5.  4.  3.  3.  2.  4.  5.  2.\n",
      "  5.  3.  5.  3.  5.  3.]\n"
     ]
    }
   ],
   "source": [
    "x_train = create_Xmatrix(x,len(x),0)\n",
    "y_train = create_Ymatrix(x,len(x),1)\n",
    "x_test = create_Xmatrix(test,len(test),0)\n",
    "y_test = create_Ymatrix(test,len(test),1)\n",
    "\n",
    "print('X_train shape:', x_train.shape)\n",
    "print('X_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/ops/gradients.py:90: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 328 samples, validate on 132 samples\n",
      "Epoch 1/15\n",
      "328/328 [==============================] - 1s - loss: 0.6918 - acc: 0.0457 - val_loss: 0.6634 - val_acc: 0.0606\n",
      "Epoch 2/15\n",
      "328/328 [==============================] - 0s - loss: 0.6644 - acc: 0.0610 - val_loss: 0.6327 - val_acc: 0.0606\n",
      "Epoch 3/15\n",
      "328/328 [==============================] - 0s - loss: 0.6299 - acc: 0.0640 - val_loss: 0.5943 - val_acc: 0.0606\n",
      "Epoch 4/15\n",
      "328/328 [==============================] - 0s - loss: 0.5869 - acc: 0.0732 - val_loss: 0.5561 - val_acc: 0.0606\n",
      "Epoch 5/15\n",
      "328/328 [==============================] - 0s - loss: 0.5668 - acc: 0.0793 - val_loss: 0.5159 - val_acc: 0.0606\n",
      "Epoch 6/15\n",
      "328/328 [==============================] - 0s - loss: 0.4955 - acc: 0.0793 - val_loss: 0.4697 - val_acc: 0.0606\n",
      "Epoch 7/15\n",
      "328/328 [==============================] - 0s - loss: 0.4471 - acc: 0.0793 - val_loss: 0.4201 - val_acc: 0.0606\n",
      "Epoch 8/15\n",
      "328/328 [==============================] - 0s - loss: 0.4452 - acc: 0.0793 - val_loss: 0.3661 - val_acc: 0.0606\n",
      "Epoch 9/15\n",
      "328/328 [==============================] - 0s - loss: 0.3356 - acc: 0.0793 - val_loss: 0.3056 - val_acc: 0.0606\n",
      "Epoch 10/15\n",
      "328/328 [==============================] - 0s - loss: 0.3169 - acc: 0.0793 - val_loss: 0.2378 - val_acc: 0.0606\n",
      "Epoch 11/15\n",
      "328/328 [==============================] - 0s - loss: 0.1965 - acc: 0.0793 - val_loss: 0.1628 - val_acc: 0.0606\n",
      "Epoch 12/15\n",
      "328/328 [==============================] - 0s - loss: 0.1176 - acc: 0.0793 - val_loss: 0.0794 - val_acc: 0.0606\n",
      "Epoch 13/15\n",
      "328/328 [==============================] - 0s - loss: 0.0206 - acc: 0.0793 - val_loss: -0.0129 - val_acc: 0.0606\n",
      "Epoch 14/15\n",
      "328/328 [==============================] - 0s - loss: -0.0832 - acc: 0.0793 - val_loss: -0.1145 - val_acc: 0.0606\n",
      "Epoch 15/15\n",
      "328/328 [==============================] - 0s - loss: -0.2104 - acc: 0.0793 - val_loss: -0.2268 - val_acc: 0.0606\n",
      "132/132 [==============================] - 0s\n",
      "Test score: -0.226787120104\n",
      "Test accuracy: 0.0606060624123\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(30000,256, dropout=0.2))\n",
    "model.add(LSTM(256, dropout_W=0.2, dropout_U=0.2))  # try using a GRU instead, for fun\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train, batch_size=328, nb_epoch=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=328)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
